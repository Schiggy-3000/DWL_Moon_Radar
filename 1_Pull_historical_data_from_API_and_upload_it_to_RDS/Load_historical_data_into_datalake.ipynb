{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "\n",
    "1. Goal\n",
    "2. Setup\n",
    "3. Connect to PostgreSQL\n",
    "4. Upload Historical Data to PostgreSQL\n",
    "5. Sample of Uploaded Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "The aim of this jupyter notebook is to upload data to a PostgreSQL database. It concerns historical data from:\n",
    "\n",
    "- CoinGecko\n",
    "- Reddit\n",
    "- Google Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you installed Python using Anaconda or Miniconda, then use conda:\n",
    "# conda install -c anaconda psycopg2\n",
    "# conda install -c anaconda sqlalchemy\n",
    "\n",
    "# If you installed Python any other way, then use pip:\n",
    "# !pip install psycopg2\n",
    "# !pip install SQLAlchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv                             # Used to insert data into tables \n",
    "import sys\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connection to PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference to documentation: https://www.psycopg.org/docs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection to postgres DB\n",
    "# Access is open to...\n",
    "# ::/0\n",
    "# 0.0.0/0\n",
    "# This is set in AWS -> RDS -> 'database name' -> VPC security groups -> select any security group -> Inbound rules -> Edit inbound rules\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(dbname   = \"datalakebisasam\",\n",
    "                            user     = \"bisasam\",\n",
    "                            password = \"1234asdf\",\n",
    "                            host     = \"datalake.clnjs1yqzw0z.us-east-1.rds.amazonaws.com\")\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error connecting to DB: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Historical Data to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a cursor to perform DB operations\n",
    "\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enabling auto-commit on existing connection\n",
    "# Otherwise if commit() is not called, the effect of any data manipulation would be lost.\n",
    "conn.autocommit = True\n",
    "\n",
    "# Check if autocommit is on/off\n",
    "#print(conn.autocommit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('template0',)\n",
      "('rdsadmin',)\n",
      "('template1',)\n",
      "('postgres',)\n",
      "('datalakebisasam',)\n"
     ]
    }
   ],
   "source": [
    "# List all DB's\n",
    "\n",
    "query = \"SELECT datname FROM pg_database;\"\n",
    "\n",
    "\n",
    "try:\n",
    "    cur.execute(query)\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "for Database in cur: \n",
    "    print(f\"{Database}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop tables if they already exist (which is the case if this notebook was executed before)\n",
    "\n",
    "query_A = \"DROP TABLE historical_coin_data;\"\n",
    "query_B = \"DROP TABLE historical_reddit_data;\"\n",
    "query_C = \"DROP TABLE historical_google_data;\"\n",
    "\n",
    "\n",
    "try:\n",
    "    cur.execute(query_A)\n",
    "    cur.execute(query_B)\n",
    "    cur.execute(query_C)\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables\n",
    "\n",
    "query_A = \"CREATE TABLE historical_coin_data (prices DOUBLE PRECISION, market_caps DOUBLE PRECISION, total_volumes DOUBLE PRECISION, coin TEXT, date TEXT, date_unix DOUBLE PRECISION);\"\n",
    "query_B = \"CREATE TABLE historical_reddit_data (post_title TEXT, num_comments INTEGER, subreddit TEXT, subreddit_subscribers INTEGER, date TEXT, date_unix DOUBLE PRECISION);\"\n",
    "query_C = \"CREATE TABLE historical_google_data (date TEXT, convex_finance INTEGER, ribbon_finance INTEGER, rari_governance_token INTEGER, gmx INTEGER, nftx INTEGER, category TEXT);\"\n",
    "\n",
    "\n",
    "try:\n",
    "    cur.execute(query_A)\n",
    "    cur.execute(query_B)\n",
    "    cur.execute(query_C)\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('public', 'historical_twitter_data', 'bisasam', None, False, False, False, False)\n",
      "('public', 'coin_cata_historical', 'bisasam', None, True, False, False, False)\n",
      "('public', 'historical_coin_data', 'bisasam', None, False, False, False, False)\n",
      "('public', 'historical_reddit_data', 'bisasam', None, False, False, False, False)\n",
      "('public', 'historical_google_data', 'bisasam', None, False, False, False, False)\n"
     ]
    }
   ],
   "source": [
    "# Show all tables in the DB we are connected\n",
    "\n",
    "query = \"SELECT * FROM pg_catalog.pg_tables WHERE schemaname != 'pg_catalog' AND schemaname != 'information_schema';\"\n",
    "\n",
    "\n",
    "try:\n",
    "    cur.execute(query)\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "for Database in cur:\n",
    "    print(f\"{Database}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('post_title', 'text')\n",
      "('num_comments', 'integer')\n",
      "('subreddit', 'text')\n",
      "('subreddit_subscribers', 'integer')\n",
      "('date', 'text')\n",
      "('date_unix', 'double precision')\n"
     ]
    }
   ],
   "source": [
    "# Get column names of table\n",
    "\n",
    "query = \"SELECT column_name, data_type FROM information_schema.columns WHERE table_name = 'historical_reddit_data';\"\n",
    "\n",
    "\n",
    "try:\n",
    "    cur.execute(query)\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "for Database in cur: \n",
    "    print(f\"{Database}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert coin data\n",
    "\n",
    "query = \"INSERT INTO historical_coin_data VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "file  = \".\\Datasets\\historical_data_coin.csv\"\n",
    "\n",
    "\n",
    "with open(file, \"r\", encoding=\"utf8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader) # Skip header row\n",
    "    for row in reader:\n",
    "        cur.execute(query, row)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert reddit data\n",
    "\n",
    "query = \"INSERT INTO historical_reddit_data VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "file  = \".\\Datasets\\historical_data_reddit.csv\"\n",
    "\n",
    "\n",
    "with open(file, \"r\", encoding=\"utf8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader) # Skip header row\n",
    "    for row in reader:\n",
    "        cur.execute(query, row)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert google data\n",
    "\n",
    "query = \"INSERT INTO historical_google_data VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "file  = \".\\Datasets\\historical_data_google.csv\"\n",
    "\n",
    "\n",
    "with open(file, \"r\", encoding=\"utf8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader) # Skip header row\n",
    "    for row in reader:\n",
    "        cur.execute(query, row)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample of Uploaded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Music NFT'S\", 0, 'ecomi', 22457, '31-10-2021', 1635690306.0)\n",
      "('Fresh music !!', 0, 'audius', 8065, '31-10-2021', 1635689985.0)\n",
      "('The Toys that Made Us', 1, 'ecomi', 22457, '31-10-2021', 1635685133.0)\n"
     ]
    }
   ],
   "source": [
    "# Show rows form table \n",
    "\n",
    "query = \"SELECT * FROM historical_reddit_data LIMIT 3;\"\n",
    "\n",
    "\n",
    "try:\n",
    "    cur.execute(query)\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "for Database in cur:\n",
    "    print(f\"{Database}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminate connection\n",
    "\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
